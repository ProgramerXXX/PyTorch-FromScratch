{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHiRnDhTVxHR",
        "outputId": "61a83de0-fe0e-44e5-c6ec-cf47b8ea27fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import numpy as np\n",
        "\n",
        "x = torch.randn(3,requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "y = x+2\n",
        "print(y)\n",
        "\n",
        "z = y*y*2\n",
        "z = z.mean()\n",
        "print(z)\n",
        "\n",
        "z.backward()\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmxxcWkEWyYC",
        "outputId": "2bc606ed-3ff2-4b76-a6f0-e08c6afed736"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.4411,  1.8900, -0.1820], requires_grad=True)\n",
            "tensor([0.5589, 3.8900, 1.8180], grad_fn=<AddBackward0>)\n",
            "tensor(12.4998, grad_fn=<MeanBackward0>)\n",
            "tensor([0.7452, 5.1867, 2.4240])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight = torch.ones(4,requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "  model = (weight*3).sum()\n",
        "  print(model)\n",
        "  model.backward()\n",
        "  print(weight.grad)\n",
        "  weight.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLSHv5M8W4ef",
        "outputId": "f22096f0-c52b-42ad-f8d0-e094a3154af3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(12., grad_fn=<SumBackward0>)\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor(12., grad_fn=<SumBackward0>)\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor(12., grad_fn=<SumBackward0>)\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "\n",
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "y_hat = w*x \n",
        "loss = (y_hat - y)**2\n",
        "\n",
        "print(loss)\n",
        "#back ward pass\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BU84eTzp_Yf",
        "outputId": "6965d9f4-402e-4660-9538-d30afff82234"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-2.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "\n",
        "# Compute every step manually\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x \n",
        "\n",
        "# here : f = 2 * x\n",
        "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
        "Y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
        "\n",
        "w = 0.0\n",
        "\n",
        "# model output\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "# loss = MSE\n",
        "def loss(y, y_pred):\n",
        "    return ((y_pred - y)**2).mean()\n",
        "\n",
        "# J = MSE = 1/N * (w*x - y)**2\n",
        "# dJ/dw = 1/N * 2x(w*x - y)\n",
        "def gradient(x, y, y_pred):\n",
        "    return np.dot(2*x, y_pred - y).mean()\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 20\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass\n",
        "    y_pred = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_pred)\n",
        "    \n",
        "    # calculate gradients\n",
        "    dw = gradient(X, Y, y_pred)\n",
        "\n",
        "    # update weights\n",
        "    w -= learning_rate * dw\n",
        "\n",
        "    if epoch % 2 == 0:\n",
        "        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "     \n",
        "print(f'Prediction after training: f(5) = {forward(5):.3f}')\n"
      ],
      "metadata": {
        "id": "Y3roOBJEumsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Here we replace the manually computed gradient with autograd\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x \n",
        "\n",
        "# here : f = 2 * x\n",
        "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# model output\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "# loss = MSE\n",
        "def loss(y, y_pred):\n",
        "    return ((y_pred - y)**2).mean()\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5).item():.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass\n",
        "    y_pred = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_pred)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    #w.data = w.data - learning_rate * w.grad\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "    \n",
        "    # zero the gradients after updating\n",
        "    w.grad.zero_()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAykS3cba448",
        "outputId": "ab06abc0-be84-47db-aa1c-8119f84c47fe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch 1: w = 0.300, loss = 30.00000000\n",
            "epoch 11: w = 1.665, loss = 1.16278565\n",
            "epoch 21: w = 1.934, loss = 0.04506890\n",
            "epoch 31: w = 1.987, loss = 0.00174685\n",
            "epoch 41: w = 1.997, loss = 0.00006770\n",
            "epoch 51: w = 1.999, loss = 0.00000262\n",
            "epoch 61: w = 2.000, loss = 0.00000010\n",
            "epoch 71: w = 2.000, loss = 0.00000000\n",
            "epoch 81: w = 2.000, loss = 0.00000000\n",
            "epoch 91: w = 2.000, loss = 0.00000000\n",
            "Prediction after training: f(5) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Design model (input, output, forward pass with different layers)\n",
        "# 2) Construct loss and optimizer\n",
        "# 3) Training loop\n",
        "#       - Forward = compute prediction and loss\n",
        "#       - Backward = compute gradients\n",
        "#       - Update weights\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x \n",
        "\n",
        "# here : f = 2 * x\n",
        "\n",
        "# 0) Training samples\n",
        "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "# 1) Design Model: Weights to optimize and forward function\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5).item():.3f}')\n",
        "\n",
        "# 2) Define loss and optimizer\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "# callable function\n",
        "loss = nn.MSELoss()\n",
        "\n",
        "optimizer = torch.optim.SGD([w], lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass\n",
        "    y_predicted = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_predicted)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print('epoch ', epoch+1, ': w = ', w, ' loss = ', l)\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TI8HNETPcqA6",
        "outputId": "53b1992e-9349-4342-a727-bcf3db905877"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch  1 : w =  tensor(0.3000, requires_grad=True)  loss =  tensor(30., grad_fn=<MseLossBackward0>)\n",
            "epoch  11 : w =  tensor(1.6653, requires_grad=True)  loss =  tensor(1.1628, grad_fn=<MseLossBackward0>)\n",
            "epoch  21 : w =  tensor(1.9341, requires_grad=True)  loss =  tensor(0.0451, grad_fn=<MseLossBackward0>)\n",
            "epoch  31 : w =  tensor(1.9870, requires_grad=True)  loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
            "epoch  41 : w =  tensor(1.9974, requires_grad=True)  loss =  tensor(6.7705e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch  51 : w =  tensor(1.9995, requires_grad=True)  loss =  tensor(2.6244e-06, grad_fn=<MseLossBackward0>)\n",
            "epoch  61 : w =  tensor(1.9999, requires_grad=True)  loss =  tensor(1.0176e-07, grad_fn=<MseLossBackward0>)\n",
            "epoch  71 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(3.9742e-09, grad_fn=<MseLossBackward0>)\n",
            "epoch  81 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(1.4670e-10, grad_fn=<MseLossBackward0>)\n",
            "epoch  91 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(5.0768e-12, grad_fn=<MseLossBackward0>)\n",
            "Prediction after training: f(5) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "bc = datasets.load_breast_cancer()\n",
        "X , y = bc.data,bc.target\n",
        "n_sample , n_feature = x.shape\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
      ],
      "metadata": {
        "id": "vxXcuIN7dJEe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKLTAwgOkIOp",
        "outputId": "8991d660-eab0-442f-9e58-81144afde613"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.288e+01, 1.822e+01, 8.445e+01, ..., 1.096e-01, 2.582e-01,\n",
              "        8.893e-02],\n",
              "       [1.113e+01, 2.244e+01, 7.149e+01, ..., 6.413e-02, 3.169e-01,\n",
              "        8.032e-02],\n",
              "       [1.263e+01, 2.076e+01, 8.215e+01, ..., 1.105e-01, 2.226e-01,\n",
              "        8.486e-02],\n",
              "       ...,\n",
              "       [1.247e+01, 1.860e+01, 8.109e+01, ..., 1.015e-01, 3.014e-01,\n",
              "        8.750e-02],\n",
              "       [1.822e+01, 1.870e+01, 1.203e+02, ..., 1.325e-01, 3.021e-01,\n",
              "        7.987e-02],\n",
              "       [1.272e+01, 1.378e+01, 8.178e+01, ..., 6.343e-02, 2.369e-01,\n",
              "        6.922e-02]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n"
      ],
      "metadata": {
        "id": "l0p4G5zGjhOI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sgLaUQujgqN",
        "outputId": "e5f26d2b-012f-4ecb-f328-3beec89f73d2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.36180827, -0.26521011, -0.31715702, ..., -0.07967528,\n",
              "        -0.52798733,  0.2506337 ],\n",
              "       [-0.8632675 ,  0.71560604, -0.85646012, ..., -0.76980239,\n",
              "         0.44312729, -0.20987332],\n",
              "       [-0.4334453 ,  0.32513895, -0.41286667, ..., -0.06601541,\n",
              "        -1.1169427 ,  0.0329492 ],\n",
              "       ...,\n",
              "       [-0.479293  , -0.17689018, -0.45697634, ..., -0.20261414,\n",
              "         0.18670009,  0.17414996],\n",
              "       [ 1.16835876, -0.15364809,  1.17466524, ...,  0.26789258,\n",
              "         0.19828067, -0.23394164],\n",
              "       [-0.40765597, -1.29715887, -0.42826344, ..., -0.78042674,\n",
              "        -0.88036793, -0.80355834]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))"
      ],
      "metadata": {
        "id": "XrGTMTgtkGZg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bK9oLB1UmIJx",
        "outputId": "03ddbeb7-8857-41c2-ae67-480f7b7026a8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3618, -0.2652, -0.3172,  ..., -0.0797, -0.5280,  0.2506],\n",
              "        [-0.8633,  0.7156, -0.8565,  ..., -0.7698,  0.4431, -0.2099],\n",
              "        [-0.4334,  0.3251, -0.4129,  ..., -0.0660, -1.1169,  0.0329],\n",
              "        ...,\n",
              "        [-0.4793, -0.1769, -0.4570,  ..., -0.2026,  0.1867,  0.1741],\n",
              "        [ 1.1684, -0.1536,  1.1747,  ...,  0.2679,  0.1983, -0.2339],\n",
              "        [-0.4077, -1.2972, -0.4283,  ..., -0.7804, -0.8804, -0.8036]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "c76k0nB_mJfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)"
      ],
      "metadata": {
        "id": "RaYe5npgmWJo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torch.nn as nn \n",
        "import numpy as np \n",
        "from sklearn import datasets \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "bc = datasets.load_breast_cancer()\n",
        "X,y = bc.data,bc.target \n",
        "\n",
        "n_samples,n_features = X.shape\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1234)\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.fit_transform(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "y_train = y_train.view(y_train.shape[0],1)\n",
        "y_test = y_test.view(y_test.shape[0],1)\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self,n_input_feature):\n",
        "    super(LogisticRegression,self).__init__()\n",
        "    self.linear = nn.Linear(n_input_feature,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    y_predicted = torch.sigmoid(self.linear(x))\n",
        "    return y_predicted \n",
        "  \n",
        "model = LogisticRegression(n_features)\n",
        "\n",
        "learning_rate = 0.01 \n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "numepoch = 100\n",
        "for epoch in range(numepoch):\n",
        "\n",
        "  y_predicted = model(X_train)\n",
        "  loss = criterion(y_predicted,y_train)\n",
        "\n",
        "  loss.backward()\n",
        "  \n",
        "  optimizer.step()\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if (epoch+1)%10 ==0:\n",
        "    print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "with torch.no_grad():\n",
        "  y_predicted = model(X_test)\n",
        "  y_predicted_cls = y_predicted.round()\n",
        "  acc = y_predicted_cls.eq(y_test).sum()/float(y_test.shape[0])\n",
        "  print(f'accuracy = {acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOj2eq_GmX8t",
        "outputId": "4c9a24be-2849-4137-c91b-d352502826cc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 0.7338\n",
            "epoch: 20, loss = 0.5611\n",
            "epoch: 30, loss = 0.4624\n",
            "epoch: 40, loss = 0.3997\n",
            "epoch: 50, loss = 0.3562\n",
            "epoch: 60, loss = 0.3240\n",
            "epoch: 70, loss = 0.2992\n",
            "epoch: 80, loss = 0.2793\n",
            "epoch: 90, loss = 0.2629\n",
            "epoch: 100, loss = 0.2492\n",
            "accuracy = 0.9210526347160339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########## pytorch_tutorial.py\n",
        "# /content/wine.csv\n",
        "\n",
        "import torch \n",
        "import torchvision \n",
        "from torch.utils.data import Dataset,DataLoader \n",
        "import numpy as np \n",
        "import math \n",
        "\n",
        "class WineDataset(Dataset):\n",
        "  \n",
        "  def __init__(self):\n",
        "    #data loading\n",
        "    xy = np.loadtxt('/content/wine.csv',delimiter=',',dtype=np.float32,skiprows=1)\n",
        "    self.x = torch.from_numpy(xy[:,1:])\n",
        "    self.y = torch.from_numpy(xy[:,[0]]) #n_sample,1\n",
        "    self.n_samples = xy.shape[0]\n",
        "    \n",
        "  def __getitem__(self,index):\n",
        "    return self.x[index], self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "\n",
        "dataset = WineDataset()\n",
        "dataloader = DataLoader(dataset=dataset,batch_size=4,shuffle=True,num_workers=2)\n",
        "# datatiter = iter(dataloader)\n",
        "# data = datatiter.next()\n",
        "# features,labels = data \n",
        "# print(features,labels)\n",
        "\n",
        "num_epoch = 2 \n",
        "total_samples = len(dataset)\n",
        "n_iterations = math.ceil(total_samples/4)\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "  for i,(inputs,labels) in enumerate(dataloader):\n",
        "      print(f\"epoch {epoch+1}/{num_epoch}, sstep {i+1}/{n_iterations}, input {inputs.shape}\")\n"
      ],
      "metadata": {
        "id": "iZyyfRdkMEnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torchvision \n",
        "from torch.utils.data import Dataset,DataLoader \n",
        "import numpy as np \n",
        "import math \n",
        "\n",
        "class WineDataset(Dataset):\n",
        "  \n",
        "  def __init__(self,transform=None):\n",
        "    #data loading\n",
        "    xy1 = np.loadtxt('/content/wine.csv',delimiter=',',dtype=np.float32,skiprows=1)\n",
        "\n",
        "    self.x1 = torch.from_numpy(xy1[:,1:])\n",
        "    self.y1 = torch.from_numpy(xy1[:,[0]]) #n_sample,1\n",
        "\n",
        "    self.transform = transform\n",
        "    \n",
        "  def __getitem__(self, index):\n",
        "    sample = self.x1[index], self.y1[index]\n",
        "\n",
        "    if self.transform:\n",
        "        sample = self.transform(sample)\n",
        "    return sample\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "\n",
        "class ToTensor:\n",
        "    # Convert ndarrays to Tensors\n",
        "    def __call__(self, sample):\n",
        "        inputs, targets = sample\n",
        "        return torch.from_numpy(np.array(inputs)), torch.from_numpy(np.array(targets))\n",
        "\n",
        "class MulTransform:\n",
        "  def __init__(self,factor):\n",
        "    self.factor = factor \n",
        "  \n",
        "  def __call__(self,sample):\n",
        "    input ,target = sample \n",
        "    input *= self.factor \n",
        "    return input , target \n",
        "\n",
        "dataset = WineDataset(transform=None)\n",
        "first_datas = dataset[1]\n",
        "features, labelss = first_datas\n",
        "print(type(features),type(labelss))\n",
        "\n",
        "composed = torchvision.transforms.Compose([ToTensor(),MulTransform(2)])\n",
        "datasets = WineDataset(transform=composed)\n",
        "first_data = datasets[1]\n",
        "feature, labels = first_data\n",
        "print(type(feature),type(labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3M53H1ak217",
        "outputId": "e02d6995-f85d-472a-cb75-1bce2eecc79e"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#feed forward "
      ],
      "metadata": {
        "id": "39Hz_Y7Tt8r0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters \n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 500 \n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset \n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
        "                                           train=True, \n",
        "                                           transform=transforms.ToTensor(),  \n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
        "                                          train=False, \n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)\n",
        "\n",
        "examples = iter(test_loader)\n",
        "example_data, example_targets = examples.next()\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.l1 = nn.Linear(input_size, hidden_size) \n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)  \n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
        "\n",
        "# Train the model\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):  \n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
      ],
      "metadata": {
        "id": "TD8I--m1nhMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN "
      ],
      "metadata": {
        "id": "xRdDqPwyuBwy"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters \n",
        "num_epochs = 1\n",
        "batch_size = 4\n",
        "learning_rate = 0.001\n",
        "\n",
        "# dataset has PILImage images of range [0, 1]. \n",
        "# We transform them to Tensors of normalized range [-1, 1]\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                         shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "\n",
        "# dataiter = iter(train_loader)\n",
        "# images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "# imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # -> n, 3, 32, 32\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 5, 5\n",
        "        x = x.view(-1, 16 * 5 * 5)            # -> n, 400\n",
        "        x = F.relu(self.fc1(x))               # -> n, 120\n",
        "        x = F.relu(self.fc2(x))               # -> n, 84\n",
        "        x = self.fc3(x)                       # -> n, 10\n",
        "        return x\n",
        "\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
        "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 2000 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print('Finished Training')\n",
        "PATH = './cnn.pth'\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for i in range(10)]\n",
        "    n_class_samples = [0 for i in range(10)]\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        x, predicted = torch.max(outputs, 1)\n",
        "        print(f'{x},{predicted}')\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        for i in range(batch_size):\n",
        "            label = labels[i]\n",
        "            pred = predicted[i]\n",
        "            if (label == pred):\n",
        "                n_class_correct[label] += 1\n",
        "            n_class_samples[label] += 1\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "    for i in range(10):\n",
        "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "        print(f'Accuracy of {classes[i]}: {acc} %')\n",
        "\n"
      ],
      "metadata": {
        "id": "t_ybC7Z1uzE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "no1-i0N2vqaj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}